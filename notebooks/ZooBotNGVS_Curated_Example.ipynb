{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb967809",
   "metadata": {},
   "source": [
    "# ZooBot Fine-Tuning on NGVS Morphology Labels (Curated Example)\n",
    "\n",
    "This notebook is a **curated** example of fine-tuning a pretrained ZooBot CNN on NGVS galaxy cutouts,\n",
    "then generating predictions and inspecting failure cases.\n",
    "\n",
    "**What this demonstrates**\n",
    "- Building a ZooBot-compatible `catalog` (`id_str`, `file_loc`, label columns)\n",
    "- Fine-tuning (head-only vs deeper-layer) via `n_layers`\n",
    "- Saving predictions to CSV for reproducible downstream analysis\n",
    "- Qualitative error inspection (top/bottom predictions; incorrect vs correct)\n",
    "\n",
    "> Note: Image data and some paths are project-specific. Replace placeholders under **Configuration**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af44d771",
   "metadata": {},
   "source": [
    "## 0) Configuration\n",
    "\n",
    "Set paths and choose a label column to train on (example: **E vs non-E**).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd0afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# --- Logging / device ---\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# --- Paths (EDIT THESE) ---\n",
    "DATA_DIR = \"/path/to/ngvs_jpegs/\"        # directory containing image files\n",
    "CATALOG_CSV = \"/path/to/ngvs_catalog.csv\"  # must include NGVS_name + morphology label columns\n",
    "CHECKPOINT_LOC = \"/path/to/zoobot_checkpoint.ckpt\"  # pretrained ZooBot checkpoint\n",
    "SAVE_DIR = \"./outputs/run_001\"            # where checkpoints + predictions will be written\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# --- Task definition ---\n",
    "# Example binary task: Elliptical (\"E\") vs non-E\n",
    "MORPH_COL = \"Morphology_code\"  # column in your catalog CSV with labels like 'E', 'ES', 'EI', ...\n",
    "LABEL_COL = \"is_E\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ed351b",
   "metadata": {},
   "source": [
    "## 1) Load catalog and build ZooBot fields\n",
    "\n",
    "ZooBot expects a pandas DataFrame (`catalog`) that includes:\n",
    "- `id_str`: unique identifier per image\n",
    "- `file_loc`: path to image file\n",
    "- label columns (e.g., `is_E`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54aa8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "catalog = pd.read_csv(CATALOG_CSV)\n",
    "\n",
    "# Required fields\n",
    "catalog[\"id_str\"] = catalog[\"NGVS_name\"].astype(str)\n",
    "catalog[\"file_loc\"] = catalog[\"id_str\"].apply(lambda x: os.path.join(DATA_DIR, f\"{x}.jpeg\"))\n",
    "\n",
    "# Drop duplicates / missing images (optional but recommended)\n",
    "catalog = catalog.drop_duplicates(subset=[\"id_str\"]).reset_index(drop=True)\n",
    "\n",
    "# Filter to rows where the image exists (avoids runtime surprises)\n",
    "catalog = catalog[catalog[\"file_loc\"].apply(os.path.exists)].reset_index(drop=True)\n",
    "\n",
    "print(\"Rows after filtering:\", len(catalog))\n",
    "catalog.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c56a0c",
   "metadata": {},
   "source": [
    "## 2) Build label column(s)\n",
    "\n",
    "Here we build a simple **binary** target: `is_E`.\n",
    "You can extend this pattern to other binary tasks or to multi-class labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf66ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary label example: E vs non-E\n",
    "catalog[LABEL_COL] = (catalog[MORPH_COL] == \"E\").astype(int)\n",
    "\n",
    "print(catalog[LABEL_COL].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dfd5d4",
   "metadata": {},
   "source": [
    "## 3) Create the ZooBot DataModule\n",
    "\n",
    "We use `GalaxyDataModule` to handle image loading, resizing/cropping, and batching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab3149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from galaxy_datasets.pytorch.galaxy_datamodule import GalaxyDataModule\n",
    "\n",
    "label_cols = [LABEL_COL]\n",
    "\n",
    "datamodule = GalaxyDataModule(\n",
    "    label_cols=label_cols,\n",
    "    catalog=catalog,\n",
    "    batch_size=32,\n",
    "    resize_after_crop=224,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "datamodule.setup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0547d8",
   "metadata": {},
   "source": [
    "## 4) Fine-tune ZooBot\n",
    "\n",
    "Key knob: `n_layers`\n",
    "- `n_layers=0` → **head-only** fine-tuning\n",
    "- `n_layers>0` → fine-tune deeper layers (more adaptation, more risk of overfitting)\n",
    "\n",
    "This code uses ZooBot's Lightning trainer helpers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zoobot.pytorch.training import finetune\n",
    "\n",
    "# Choose head-only vs deeper fine-tuning\n",
    "N_LAYERS_TO_FINETUNE = 0   # 0=head-only; try 2 for deeper fine-tune\n",
    "\n",
    "model = finetune.FinetuneableZoobotClassifier(\n",
    "    checkpoint_loc=CHECKPOINT_LOC,\n",
    "    num_classes=2,\n",
    "    n_layers=N_LAYERS_TO_FINETUNE,\n",
    ")\n",
    "\n",
    "trainer = finetune.get_trainer(\n",
    "    save_dir=SAVE_DIR,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    max_epochs=50,  # adjust as needed\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule)\n",
    "best_checkpoint = trainer.checkpoint_callback.best_model_path\n",
    "print(\"Best checkpoint:\", best_checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16ae0b",
   "metadata": {},
   "source": [
    "## 5) Predict on the full catalog and save to CSV\n",
    "\n",
    "Saving predictions makes your experiment reproducible and enables analysis without re-running inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zoobot.pytorch.predictions import predict_on_catalog\n",
    "\n",
    "finetuned_model = finetune.FinetuneableZoobotClassifier.load_from_checkpoint(best_checkpoint)\n",
    "\n",
    "PRED_CSV = os.path.join(SAVE_DIR, \"finetuned_predictions.csv\")\n",
    "\n",
    "predict_on_catalog.predict(\n",
    "    catalog=catalog,\n",
    "    model=finetuned_model,\n",
    "    n_samples=1,\n",
    "    label_cols=label_cols,\n",
    "    save_loc=PRED_CSV,\n",
    "    trainer_kwargs={\"accelerator\": \"auto\", \"devices\": \"auto\"},\n",
    "    datamodule_kwargs={\"num_workers\": 2},\n",
    ")\n",
    "\n",
    "print(\"Wrote:\", PRED_CSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea00490",
   "metadata": {},
   "source": [
    "## 6) Merge predictions with labels + quick diagnostics\n",
    "\n",
    "At minimum, compute accuracy and inspect confidence extremes.\n",
    "If you later add calibration plots (reliability diagram / ECE), this is where it fits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv(PRED_CSV)\n",
    "\n",
    "# ZooBot prediction column names depend on label name; in many setups you will see something like f\"{LABEL_COL}_pred\"\n",
    "# We'll infer it robustly:\n",
    "pred_col = None\n",
    "for c in pred.columns:\n",
    "    if c.endswith(\"_pred\") and LABEL_COL in c:\n",
    "        pred_col = c\n",
    "        break\n",
    "if pred_col is None:\n",
    "    # fallback: take the first *_pred column\n",
    "    pred_col = [c for c in pred.columns if c.endswith(\"_pred\")][0]\n",
    "\n",
    "df = pred.merge(\n",
    "    catalog[[\"id_str\", \"file_loc\", LABEL_COL, MORPH_COL]],\n",
    "    on=\"id_str\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df[\"pred_label\"] = (df[pred_col] >= 0.5).astype(int)\n",
    "acc = (df[\"pred_label\"] == df[LABEL_COL]).mean()\n",
    "print(\"Accuracy:\", round(acc, 4))\n",
    "\n",
    "df[[ \"id_str\", MORPH_COL, LABEL_COL, pred_col]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae301c46",
   "metadata": {},
   "source": [
    "## 7) Qualitative failure inspection (high-signal)\n",
    "\n",
    "This is the most reviewer-friendly artifact:\n",
    "- show the **highest-confidence positives** and **lowest-confidence positives**\n",
    "- highlight incorrect predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44067194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_grid(subdf, pred_col, n=6, ncols=3, title=None):\n",
    "    n = min(n, len(subdf))\n",
    "    nrows = int(np.ceil(n / ncols))\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(4*ncols, 3.5*nrows))\n",
    "    axes = np.array(axes).reshape(-1)\n",
    "\n",
    "    for i in range(n):\n",
    "        row = subdf.iloc[i]\n",
    "        im = Image.open(row[\"file_loc\"])\n",
    "        axes[i].imshow(im)\n",
    "\n",
    "        correct = int(row[\"pred_label\"]) == int(row[LABEL_COL])\n",
    "        color = \"white\" if correct else \"red\"\n",
    "\n",
    "        axes[i].text(0.02, 0.92, f\"True: {row[LABEL_COL]}\", color=color, transform=axes[i].transAxes, fontsize=11)\n",
    "        axes[i].text(0.02, 0.82, f\"Pred: {row[pred_col]:.2f}\", color=color, transform=axes[i].transAxes, fontsize=11)\n",
    "        axes[i].text(0.02, 0.08, f\"{row[MORPH_COL]}\", color=color, transform=axes[i].transAxes, fontsize=10)\n",
    "\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    for j in range(n, len(axes)):\n",
    "        axes[j].axis(\"off\")\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Top confidence positives / bottom confidence positives\n",
    "top = df.sort_values(pred_col, ascending=False).head(9)\n",
    "bot = df.sort_values(pred_col, ascending=True).head(9)\n",
    "\n",
    "fig1 = show_grid(top, pred_col, n=9, title=\"Highest-confidence predictions\")\n",
    "fig2 = show_grid(bot, pred_col, n=9, title=\"Lowest-confidence predictions\")\n",
    "\n",
    "# Save curated figures\n",
    "FIG_DIR = os.path.join(SAVE_DIR, \"figures\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "fig1.savefig(os.path.join(FIG_DIR, \"top_confidence.png\"), dpi=200)\n",
    "fig2.savefig(os.path.join(FIG_DIR, \"bottom_confidence.png\"), dpi=200)\n",
    "print(\"Saved figures to:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e260405",
   "metadata": {},
   "source": [
    "## 8) Next steps (optional)\n",
    "\n",
    "To make this repo application-ready, consider adding:\n",
    "- a reliability diagram / expected calibration error (ECE)\n",
    "- stratified error analysis (e.g., performance vs image quality / magnitude / subtype)\n",
    "- a small `scripts/` entry point that runs sections 0–6 without the notebook\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
